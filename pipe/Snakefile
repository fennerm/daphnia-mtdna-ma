"""Megadaph mtDNA sequence processing pipeline

Snakemake: https://snakemake.readthedocs.io/en/stable/

Input files: Paired end whole genome short read illumina sequencing from
D. pulex and D. magna
"""
import os

from plumbum.cmd import nbases

# ==============================================================================
# Set up
# ==============================================================================

configfile: "config.yml"
SAMPLE, PAIR = glob_wildcards("input/reads/{sample}.{pair}.fastq.gz")
SAMPLE = sorted(list(set(SAMPLE)))
PAIR = sorted(list(set(PAIR)))
PULEX = [x for x in SAMPLE if x.startswith(('L', 'T'))]
MAGNA = [x for x in SAMPLE if x.startswith(('F', 'G', 'I'))]
SPECIES = ['pulex', 'magna']
GENOME = ['nuc', 'all', 'mt.og', 'mt.rot']
GENOTYPE = ['FA', 'FB', 'FC', 'GA', 'GB', 'GC', 'IA', 'IB', 'IC', 'L', 'TCO']
ROTATION = ['og', 'rot']

# Get all non-control sample IDs
NONCONTROL = [x for x in SAMPLE if not ('SC' in x) and not ('EC' in x)]
# Assign each non-control sample to a genotype
GENOTYPE_EXP = {}
for genotype in GENOTYPE:
    GENOTYPE_EXP[genotype] = [x for x in NONCONTROL if x.startswith(genotype)]

print("GROUPS")
print("------")
print("Samples: " + ', '.join(SAMPLE))
print("Pulex: " + ', '.join(PULEX))
print("Magna: " + ', '.join(MAGNA))
print("Noncontrol: " + ', '.join(NONCONTROL))
print("Genotype Samples:")
print(GENOTYPE_EXP)

# ==============================================================================
# Helper functions
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Used to match the correct species or reference genome to the input files
# ==============================================================================

def species(wildcards):
    """Determine the species from the sample wildcard"""
    if wildcards.sample in PULEX:
        spp = 'pulex'
    elif wildcards.sample in MAGNA:
        spp = 'magna'
    else:
        raise ValueError('Could not assign species to sample')
    return spp

def indices(reference):
    """Given the name of a reference seq, return the names of its indices"""
    idx = {}
    prefix = os.path.splitext(reference)[0]
    for (tool, suffix) in [("picard_idx", ".dict"), ("bowtie2_idx", ".1.bt2"),
                           ("samtools_idx", ".fa.fai")]:
        idx[tool] = prefix + suffix
    return idx

def add_indices(reference):
    """Given the name of a fasta, combine it with its indices in a dict"""
    outdict = indices(reference)
    outdict["ref"] = reference
    return outdict


def get_nbases(wildcards):
    spp = species(wildcards)
    bp = nbases("ref/" + spp + ".mt.og.fa").split("\n")[0]
    return bp


def reference(wildcards):
    """Get the paths to the original or rotated mtDNA fasta and their indices"""
    name = '.'.join([species(wildcards), "mt", wildcards.rotation, "fa"])
    ref = os.path.join("ref", name)
    return add_indices(ref)


def rotated_reference(wildcards):
    """Get the paths to the rotated mtDNA fasta and its indices"""
    name = species(wildcards) + ".mt.rot.fa"
    ref = os.path.join("ref", name)
    return add_indices(ref)


def combined_reference(wildcards):
    """Get the path to the combined nuclear + mtDNA fasta and their indices"""
    ref = os.path.join("ref", species(wildcards) + ".all.fa")
    return add_indices(ref)


def prefix(wildcards):
    """Return the filename prefix of the input file"""
    return os.path.splitext(wildcards.input)[0]


def bowtie2_idx_root(idx):
    """Given the path to a forward bowtie2 index, return its root name"""
    return os.path.splitext(os.path.splitext(idx)[0])[0]

# ==============================================================================
# Pipeline
# ==============================================================================

rule all:
    input:
        "output/multiqc/multiqc.html",
        "output/merge_variants/variants.csv",
        expand(["ref/{species}.{genome}.1.bt2", "ref/{species}.{genome}.dict",
               "ref/{species}.{genome}.fa.fai"], species=SPECIES,
               genome=GENOME),
        expand("output/qualimap/{sample}_{rotation}/genome_results.txt", 
               sample=SAMPLE, rotation=ROTATION)

rule rotate_reference:
    input:
        'ref/{species}.mt.og.fa'
    output:
        'ref/{species}.mt.rot.fa'
    shell:
        "scripts/rotate_ref.py {input} {output}"


rule combine_mt_and_nuc_references:
    input:
        nuc = 'ref/{species}.nuc.fa',
        og = 'ref/{species}.mt.og.fa',
        rot = 'ref/{species}.mt.rot.fa'
    output:
        'ref/{species}.all.fa'
    shell:
        "cat {input.og} {input.rot} {input.nuc} > {output}"

rule index_references:
    input:
        "ref/{species}.{genome}.fa"
    output:
        "ref/{species}.{genome}.1.bt2",
        "ref/{species}.{genome}.dict",
        "ref/{species}.{genome}.fa.fai"
    shell:
        "index_fasta.py {input}"

rule raw_fastqc:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        'output/raw_fastqc/{sample}.R1_fastqc.html',
        'output/raw_fastqc/{sample}.R2_fastqc.html',
    params:
        outdir = 'output/raw_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads}"

rule trim_adapters:
    input:
        fwd_reads = 'input/reads/{sample}.R1.fastq.gz',
        rev_reads = 'input/reads/{sample}.R2.fastq.gz'
    output:
        fwd_reads = 'output/trim_adapters/{sample}.R1.fastq.gz',
        rev_reads = 'output/trim_adapters/{sample}.R2.fastq.gz'
    log: "output/trim_adapters/log/{sample}.log"
    params:
        ref = config['adapters'],
        k = '23',
        ktrim = 'r',
        mink = '4',
        hdist = '1'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} threads=1 "
        "out={output.fwd_reads} out2={output.rev_reads} ref={params.ref} "
        "k={params.k} ktrim={params.ktrim} mink={params.mink} "
        "hdist={params.hdist} tpe tbo 2> {log}"

rule quality_trim:
    input:
        fwd_reads = 'output/trim_adapters/{sample}.R1.fastq.gz',
        rev_reads = 'output/trim_adapters/{sample}.R2.fastq.gz'
    output:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz'
    log:
        "output/quality_trim/log/{sample}.paired.log"
    params:
        qtrim = 'rl',
        trimq = '20',
        minlen = '50'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} "
        "out={output.fwd_reads} out2={output.rev_reads} threads=1 "
        "qtrim={params.qtrim} trimq={params.trimq} minlen={params.minlen} "
        "2> {log}"

rule clean_fastqc:
    input:
        'output/quality_trim/{sample}.{pair}.fastq.gz'
    output:
        'output/clean_fastqc/{sample}.{pair}_fastqc.html'
    params:
        outdir='output/clean_fastqc'
    shell:
        "fastqc -o {params.outdir} {input}"


rule competitive_align:
    input:
        unpack(combined_reference),
        fwd_reads = "output/quality_trim/{sample}.R1.fastq.gz",
        rev_reads = "output/quality_trim/{sample}.R2.fastq.gz"
    output:
        bam = "output/competitive_align/{sample}.bam",
        bai = "output/competitive_align/{sample}.bam.bai"
    params:
        max_insert_size = '16000'
    threads:
        16
    resources:
        mem_mb = 30000
    log:
        "output/competitive_align/log/{sample}.log"
    run:
        ref_idx = bowtie2_idx_root(input.bowtie2_idx)
        shell("align_and_sort.py -1 {input.fwd_reads} "
              "-2 {input.rev_reads} -x " + ref_idx + " -p {threads} -X "
              "{params.max_insert_size} 2> {log} > {output.bam}")
        shell("samtools index {output.bam}")

rule extract_mt_reads:
    input:
        "output/competitive_align/{sample}.bam"
    output:
        fwd_reads = "output/extract_mt_reads/{sample}.R1.fastq",
        rev_reads = "output/extract_mt_reads/{sample}.R2.fastq",
        unpaired_reads = "output/extract_mt_reads/{sample}.unpaired.fastq"
    script:
        "scripts/extract_mt_reads.py"


rule align_to_mt_rotation:
    input:
        unpack(reference),
        fwd_reads = "output/extract_mt_reads/{sample}.R1.fastq",
        rev_reads = "output/extract_mt_reads/{sample}.R2.fastq"
    output:
        bam = "output/align_to_mt_rotation/{sample}.{rotation}.bam",
        bai = "output/align_to_mt_rotation/{sample}.{rotation}.bam.bai"
    resources:
        mem_mb = 2000
    params:
        max_insert_size = 16000
    log:
        "output/align_to_mt_rotation/log/{sample}.{rotation}.log"
    run:
        ref_idx = bowtie2_idx_root(input.bowtie2_idx)
        shell("scripts/align_and_sort.py -1 {input.fwd_reads} "
              "-2 {input.rev_reads} -x " + ref_idx + " -X "
              "{params.max_insert_size} --very-sensitive "
              "--rg-id={wildcards.sample} "
              "--rg=LIB:{wildcards.sample} --rg=PL:illumina "
              "--rg=SM:{wildcards.sample} > {output.bam} 2> {log}")
        shell("samtools index {output.bam}")

rule remove_duplicates:
    input:
        "output/align_to_mt_rotation/{sample}.{rotation}.bam"
    output:
        "output/remove_duplicates/{sample}.{rotation}.bam"
    log:
        "output/remove_duplicates/log/{sample}.{rotation}.log"
    resources:
        mem_mb = 2000
    shell:
        "picard MarkDuplicates I={input} O={output} REMOVE_DUPLICATES=True "
        "METRICS_FILE={log} CREATE_INDEX=True"

rule local_realignment:
    input:
        unpack(reference),
        bam = "output/remove_duplicates/{sample}.{rotation}.bam"
    output:
        bam = "output/local_realignment/{sample}.{rotation}.bam",
        intervals = "output/local_realignment/{sample}.{rotation}.intervals"
    params:
        max_move = '500',
        max_cons_reads = '300',
        max_realignment_reads = '1000000',
        max_cons = '100'
    resources:
        mem_mb = 2000
    log:
        "output/local_realignment/log/{sample}.{rotation}.log"
    script:
        "scripts/local_realign.py"

rule mismatch_filter:
    input:
        "output/local_realignment/{sample}.{rotation}.bam"
    output:
        bam = "output/mismatch_filter/{sample}.{rotation}.bam",
        bai = "output/mismatch_filter/{sample}.{rotation}.bam.bai"
    resources:
        mem_mb = 2000
    shell:
        "bamtools filter -tag 'NM:<10' -in {input} -out {output.bam} && "
        "samtools index {output.bam}"
        
rule remove_singletons:
    input:
        "output/mismatch_filter/{sample}.{rotation}.bam"
    output:
        bam = "output/remove_singletons/{sample}.{rotation}.bam",
        bai = "output/remove_singletons/{sample}.{rotation}.bam.bai"
    resources:
        mem_mb = 2000
    shell:
        "bamtools filter -isMateMapped true -in {input} -out {output.bam} && "
        "samtools index {output.bam}"

rule qualimap:
    input:
        "output/remove_singletons/{sample}.{rotation}.bam"
    output:
        "output/qualimap/{sample}_{rotation}/genome_results.txt"
    resources:
        mem_mb = 2000
    shell:
        "qualimap bamqc -bam {input} -outdir {output}"

rule randomly_select_nuclear_csomes:
    input:
        expand("output/competitive_align/{sample}.bam", sample=SAMPLE)
    output:
        magna = "output/randomly_select_nuclear_csomes/magna.txt",
        pulex = "output/randomly_select_nuclear_csomes/pulex.txt"
    params:
        n = 10000
    script:
        "scripts/randomly_select_nuclear_csomes.py"

rule subsample_nuclear_alignments:
    input:
        csome_list = lambda wildcards: os.path.join(
            "output/randomly_select_nuclear_csomes", species(wildcards) + ".txt"
            ),
        bam = "output/competitive_align/{sample}.bam"
    output:
        bam = "output/subsample_nuclear_alignments/{sample}.bam",
        bai = "output/subsample_nuclear_alignments/{sample}.bam.bai"
    run:
        with open(input.csome_list) as f:
            # Read the list of target chromosomes into a space-separated string
            target_csomes = ' '.join(f.read().split("\n"))
        shell("extract_csome {input.bam} " + target_csomes + " | "
              "samtools sort - > {output.bam}")
        shell("samtools index {output.bam}")

rule estimate_sequencing_error:
    input:
        "output/subsample_nuclear_alignments/{sample}.bam"
    output:
        "output/estimate_sequencing_error/{sample}.csv"
    resources:
        mem_mb = 15000
    shell:
        "scripts/estimate_seq_error.R {input} {output}"

rule merge_sequencing_error_files:
    input:
        lambda wildcards: [os.path.join(
            "output", "estimate_sequencing_error", x + ".csv")
            for x in GENOTYPE_EXP[wildcards.genotype]]
    output:
        "output/merge_sequencing_error_files/{genotype}.csv"
    resources:
        mem_mb = 500
    run:
        basenames = [os.path.basename(x) for x in input]
        samples = [x for x in basenames if x.startswith(wildcards.genotype)]
        samples = ["output/estimate_sequencing_error/" + x for x in samples]
        if samples:
            shell("scripts/merge_sequencing_error_files.R --output "
                  + "output/merge_sequencing_error_files/" + wildcards.genotype
                  + ".csv " + ' '.join(samples))

rule produce_spliced_pileups:
    input:
        og_bam = "output/remove_singletons/{sample}.og.bam",
        rot_bam = "output/remove_singletons/{sample}.rot.bam"
    output:
        "output/produce_spliced_pileups/{sample}.csv"
    params:
        bp = get_nbases
    resources:
        mem_mb = 500
    shell:
        "scripts/produce_spliced_pileups.R --bp {params.bp} --output "
        "{output} {input.og_bam} {input.rot_bam}"

rule call_variants:
    input:
        pile = lambda wildcards: [os.path.join(
            "output", "produce_spliced_pileups", x + ".csv")
            for x in GENOTYPE_EXP[wildcards.genotype]],
        seqerr = "output/merge_sequencing_error_files/{genotype}.csv"
    output:
        "output/call_variants/mut_cov_matrices/{genotype}.Rds",
        "output/call_variants/test_tables/{genotype}.csv",
        "output/call_variants/consensus_seqs/{genotype}.fasta"
    resources:
        mem_mb = 500
    shell:
        "scripts/call_variants.R --seqerr {input.seqerr} --output_dir "
        "output/call_variants {input.pile}"


rule correct_for_multiple_comparisons:
    input:
        piles = expand("output/call_variants/test_tables/{genotype}.csv", 
                       genotype = GENOTYPE)
    output:
        expand("output/correct_for_multiple_comparisons/{genotype}.csv", 
               genotype = GENOTYPE)
    params:
        fdr_level = "0.05"
    shell:
        "scripts/correct_for_multiple_comparisons.R --fdr {params.fdr_level} "
        "--outdir output/correct_for_multiple_comparisons {input.piles}"

rule filter_variants:
    input:
        "output/correct_for_multiple_comparisons/{genotype}.csv"
    output:
        "output/filter_variants/{genotype}.csv"
    params:
        max_strand_bias = "60"
    shell:
        "scripts/filter_variants.R --max_strand_bias {params.max_strand_bias} "
        "--output {output} {input}"

rule merge_variants:
    input:
        expand("output/filter_variants/{genotype}.csv", genotype = GENOTYPE)
    output:
        "output/merge_variants/variants.csv"
    resources:
        mem_mb = 1000
    shell:
        "csvcat {input} > {output}"

rule multiqc:
    input:
        expand(['output/clean_fastqc/{sample}.{pair}_fastqc.html',
               'output/raw_fastqc/{sample}.{pair}_fastqc.html'],
               sample=SAMPLE, pair=PAIR),
        expand("output/qualimap/{sample}_{rotation}/genome_results.txt",
               sample=SAMPLE, rotation=ROTATION)
    output:
        report = 'output/multiqc/multiqc.html',
        data = "output/multiqc/multiqc_data"
    shell:
        'rm -rf {output.data}; multiqc -d -n {output.report} .'
