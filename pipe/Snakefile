"""Megadaph mtDNA sequence processing pipeline

Snakemake: https://snakemake.readthedocs.io/en/stable/

Input files: Paired end whole genome short read illumina sequencing from
D. pulex and D. magna
"""
import os

# ==============================================================================
# Set up
# ==============================================================================

configfile: "config.yml"
SAMPLE, PAIR = glob_wildcards("input/reads/{sample}.{pair}.fastq.gz")
SAMPLE = sorted(list(set(SAMPLE)))
PAIR = sorted(list(set(PAIR)))
PULEX = [x for x in SAMPLE if x.startswith(('L', 'T'))]
MAGNA = [x for x in SAMPLE if x.startswith(('F', 'G', 'I'))]
SPECIES = ['pulex', 'magna']
GENOME = ['nuc', 'all', 'mt.og', 'mt.rot']
GENOTYPE = ['FA', 'FB', 'FC', 'GA', 'GB', 'GC', 'IA', 'IB', 'IC', 'L', 'TCO']

# Assign each sample to a genotype
GENOTYPE_SAMPLE = {}
for genotype in GENOTYPE:
    GENOTYPE_SAMPLE["genotype"] = [x for x in SAMPLE if x.startswith(genotype)]

ROTATION = ['og', 'rot']

# ==============================================================================
# Helper functions
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Used to match the correct species or reference genome to the input files
# ==============================================================================

def species(wildcards):
    """Determine the species from the sample wildcard"""
    if wildcards.sample in PULEX:
        spp = 'pulex'
    elif wildcards.sample in MAGNA:
        spp = 'magna'
    else:
        raise ValueError('Could not assign species to sample')
    return spp

def indices(reference):
    """Given the name of a reference seq, return the names of its indices"""
    idx = {}
    prefix = os.path.splitext(reference)[0]
    for (tool, suffix) in [("picard_idx", ".dict"), ("bowtie2_idx", ".1.bt2"),
                           ("samtools_idx", ".fa.fai")]:
        idx[tool] = prefix + suffix
    return idx

def add_indices(reference):
    """Given the name of a fasta, combine it with its indices in a dict"""
    outdict = indices(reference)
    outdict["ref"] = reference
    return outdict


def reference(wildcards):
    """Get the paths to the original or rotated mtDNA fasta and their indices"""
    name = '.'.join([species(wildcards), "mt", wildcards.rotation, "fa"])
    ref = os.path.join("ref", name)
    return add_indices(ref)


def rotated_reference(wildcards):
    """Get the paths to the rotated mtDNA fasta and its indices"""
    name = species(wildcards) + ".mt.rot.fa"
    ref = os.path.join("ref", name)
    return add_indices(ref)


def combined_reference(wildcards):
    """Get the path to the combined nuclear + mtDNA fasta and their indices"""
    ref = os.path.join("ref", species(wildcards) + ".all.fa")
    return add_indices(ref)


def prefix(wildcards):
    """Return the filename prefix of the input file"""
    return os.path.splitext(wildcards.input)[0]


def bowtie2_idx_root(idx):
    """Given the path to a forward bowtie2 index, return its root name"""
    return os.path.splitext(os.path.splitext(idx)[0])[0]

# ==============================================================================
# Pipeline
# ==============================================================================

rule all:
    input:
        "output/multiqc/multiqc.html",
        expand("output/qualimap/{sample}_{rotation}/", sample=SAMPLE,
               rotation=ROTATION),
        expand(["ref/{species}.{genome}.1.bt2", "ref/{species}.{genome}.dict",
               "ref/{species}.{genome}.fa.fai"], species=SPECIES,
               genome=GENOME),
        expand("output/estimate_sequencing_error/{sample}.csv",
               sample=SAMPLE)

rule rotate_reference:
    input:
        'ref/{species}.mt.og.fa'
    output:
        'ref/{species}.mt.rot.fa'
    shell:
        "scripts/rotate_ref.py {input} {output}"


rule combine_mt_and_nuc_references:
    input:
        nuc = 'ref/{species}.nuc.fa',
        og = 'ref/{species}.mt.og.fa',
        rot = 'ref/{species}.mt.rot.fa'
    output:
        'ref/{species}.all.fa'
    shell:
        "cat {input.og} {input.rot} {input.nuc} > {output}"

rule index_references:
    input:
        "ref/{species}.{genome}.fa"
    output:
        "ref/{species}.{genome}.1.bt2",
        "ref/{species}.{genome}.dict",
        "ref/{species}.{genome}.fa.fai"
    shell:
        "scripts/index_fasta.py {input}"

rule convert_quality_scores:
    input:
        'input/reads/{sample}.{rotation}.fastq.gz'
    output:
        'output/convert_quality_scores/{sample}.{rotation}.fastq.gz'
    threads: 4
    shell:
        "seqkit convert --threads {threads} {input} | gzip - > {output}"

rule raw_fastqc:
    input:
        fwd_reads = 'output/convert_quality_scores/{sample}.R1.fastq.gz',
        rev_reads = 'output/convert_quality_scores/{sample}.R2.fastq.gz'
    output:
        'output/raw_fastqc/{sample}.R1_fastqc.html',
        'output/raw_fastqc/{sample}.R2_fastqc.html',
    params:
        outdir = 'output/raw_fastqc'
    shell:
        "fastqc -o {params.outdir} {input.fwd_reads} {input.rev_reads}"

rule trim_adapters:
    input:
        fwd_reads = 'output/convert_quality_scores/{sample}.R1.fastq.gz',
        rev_reads = 'output/convert_quality_scores/{sample}.R2.fastq.gz'
    output:
        fwd_reads = 'output/trim_adapters/{sample}.R1.fastq.gz',
        rev_reads = 'output/trim_adapters/{sample}.R2.fastq.gz'
    log: "output/trim_adapters/log/{sample}.log"
    params:
        ref = config['adapters'],
        k = '23',
        ktrim = 'r',
        mink = '4',
        hdist = '1'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} threads=1 "
        "out={output.fwd_reads} out2={output.rev_reads} ref={params.ref} "
        "k={params.k} ktrim={params.ktrim} mink={params.mink} "
        "hdist={params.hdist} tpe tbo 2> {log}"

rule quality_trim:
    input:
        fwd_reads = 'output/trim_adapters/{sample}.R1.fastq.gz',
        rev_reads = 'output/trim_adapters/{sample}.R2.fastq.gz'
    output:
        fwd_reads = 'output/quality_trim/{sample}.R1.fastq.gz',
        rev_reads = 'output/quality_trim/{sample}.R2.fastq.gz'
    log:
        "output/quality_trim/log/{sample}.paired.log"
    params:
        qtrim = 'rl',
        trimq = '20',
        minlen = '50'
    shell:
        "bbduk.sh in={input.fwd_reads} in2={input.rev_reads} "
        "out={output.fwd_reads} out2={output.rev_reads} threads=1 "
        "qtrim={params.qtrim} trimq={params.trimq} minlen={params.minlen} "
        "2> {log}"

rule clean_fastqc:
    input:
        'output/quality_trim/{sample}.{pair}.fastq.gz'
    output:
        'output/clean_fastqc/{sample}.{pair}_fastqc.html'
    params:
        outdir='output/clean_fastqc'
    shell:
        "fastqc -o {params.outdir} {input}"


rule competitive_align:
    input:
        unpack(combined_reference),
        fwd_reads = "output/quality_trim/{sample}.R1.fastq.gz",
        rev_reads = "output/quality_trim/{sample}.R2.fastq.gz"
    output:
        bam = "output/competitive_align/{sample}.bam",
        bai = "output/competitive_align/{sample}.bam.bai"
    params:
        max_insert_size = '16000'
    threads:
        16
    log:
        "output/competitive_align/log/{sample}.log"
    run:
        ref_idx = bowtie2_idx_root(input.bowtie2_idx)
        shell("scripts/align_and_sort.py -1 {input.fwd_reads} "
              "-2 {input.rev_reads} -x " + ref_idx + " -p {threads} -X "
              "{params.max_insert_size} 2> {log} > {output.bam}")
        shell("samtools index {output.bam}")

rule extract_mt_reads:
    input:
        unpack(combined_reference),
        bam = "output/competitive_align/{sample}.bam"
    output:
        fwd_reads = "output/mt_aligned/{sample}.R1.fastq",
        rev_reads = "output/mt_aligned/{sample}.R2.fastq",
        unpaired_reads = "output/mt_aligned/{sample}.unpaired.fastq"
    script:
        "scripts/extract_mt_reads.py"

rule extract_nuclear_alignments:
    input:
        "output/competitive_align/{sample}.bam"
    output:
        "output/extract_nuclear_alignments/{sample}.bam"
    script:
        "scripts/extract_nuclear_alignments.py"

rule align_to_mt_rotation:
    input:
        unpack(reference),
        fwd_reads = "output/mt_aligned/{sample}.R1.fastq",
        rev_reads = "output/mt_aligned/{sample}.R2.fastq"
    output:
        bam = "output/align_to_mt_rotation/{sample}.{rotation}.bam",
        bai = "output/align_to_mt_rotation/{sample}.{rotation}.bam.bai"
    params:
        max_insert_size = 16000
    log:
        "output/align_to_mt_rotation/log/{sample}.{rotation}.log"
    run:
        ref_idx = bowtie2_idx_root(input.bowtie2_idx)
        shell("scripts/align_and_sort.py -1 {input.fwd_reads} "
              "-2 {input.rev_reads} -x " + ref_idx + " -X "
              "{params.max_insert_size} --very-sensitive "
              "--rg-id={wildcards.sample} "
              "--rg=LIB:{wildcards.sample} --rg=PL:illumina "
              "--rg=SM:{wildcards.sample} > {output.bam} 2> {log}")
        shell("samtools index {output.bam}")

rule remove_duplicates:
    input:
        "output/align_to_mt_rotation/{sample}.{rotation}.bam"
    output:
        "output/remove_duplicates/{sample}.{rotation}.bam"
    log:
        "output/remove_duplicates/log/{sample}.{rotation}.log"
    shell:
        "picard MarkDuplicates I={input} O={output} REMOVE_DUPLICATES=True "
        "METRICS_FILE={log} CREATE_INDEX=True"

rule local_realignment:
    input:
        unpack(reference),
        bam = "output/remove_duplicates/{sample}.{rotation}.bam"
    output:
        bam = "output/local_realignment/{sample}.{rotation}.bam",
        intervals = "output/local_realignment/{sample}.{rotation}.intervals"
    params:
        max_move = '500',
        max_cons_reads = '300',
        max_realignment_reads = '1000000',
        max_cons = '100'
    log:
        "output/local_realignment/log/{sample}.{rotation}.log"
    script:
        "scripts/local_realign.py"

rule remove_singletons:
    input:
        "output/local_realignment/{sample}.{rotation}.bam"
    output:
        "output/remove_singletons/{sample}.{rotation}.bam"
    shell:
        "bamtools filter -isMateMapped true -in {input} -out {output}"

rule qualimap:
    input:
        "output/remove_singletons/{sample}.{rotation}.bam"
    output:
        "output/qualimap/{sample}_{rotation}/"
    shell:
        "qualimap bamqc -bam {input} -outdir output/qualimap"

rule estimate_sequencing_error:
    input:
        "output/extract_nuclear_alignments/{sample}.bam"
    output:
        "output/estimate_sequencing_error/{sample}.csv"
    shell:
        "scripts/estimate_seq_error.R {input} {output}"

#rule merge_sequencing_error_files:
#    input:
#        lambda wildcards: os.path.join(
#            "output", "estimate_sequencing_error",
#            GENOTYPE_SAMPLE[wildcards.genotype] + ".csv")
#    output:
#        "output/merge_sequencing_error_files/{genotype}.csv"
#    run:
#        basenames = [os.path.basename(x) for x in input]
#        samples = [x for x in basenames if x.startswith(genotype)]
#        samples = ["output/estimate_sequencing_error/" + x for x in samples]
#        if samples:
#            shell("scripts/merge_sequencing_error_files.R --output "
#                  + "output/merge_sequencing_error_files/" + genotype
#                  + ".csv " + ' '.join(samples))
#
# rule produce_spliced_pileups:
#     input:
#         og_bam = "output/remove_singletons/{sample}.og.bam",
#         rot_bam = "output/remove_singletons/{sample}.rot.bam"
#     output:
#         "output/produce_spliced_pileups/{sample}.csv"
#     shell:
#         "scripts/produce_spliced_pileups.R --output {output} {input.og_bam} "
#         "{input.rot_bam}"
#
# rule call_variants:
#     input:
#         pile = expand("output/produce_spliced_pileups/{sample}.csv",
#                       sample=SAMPLE)


rule multiqc:
    input:
        expand(['output/clean_fastqc/{sample}.{pair}_fastqc.html',
               'output/raw_fastqc/{sample}.{pair}_fastqc.html'],
               sample=SAMPLE, pair=PAIR),
        expand("output/qualimap/{sample}_{rotation}/",
               sample=SAMPLE, rotation=ROTATION)
    output:
        report = 'output/multiqc/multiqc.html',
        data = "output/multiqc/multiqc_data"
    shell:
        'multiqc -d -n {output.report} .'

